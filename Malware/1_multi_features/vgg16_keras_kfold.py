import os
import glob
import numpy as np
import cv2
import time
import random
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.neighbors import KNeighborsClassifier
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.layers import Flatten
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Activation
from tensorflow.keras import losses
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import LeakyReLU
from keras import regularizers
import keras
import tensorflow as tf
from keras.utils import np_utils
from tensorflow.python.framework import ops
ops.reset_default_graph()
import warnings
warnings.filterwarnings('ignore')
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0"
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import wandb
from wandb.keras import WandbCallback
wandb.init(project="vgg16-malimg-colormap")
def num_img_fams_list():
    '''
    统计每个家族中的样本数
    :return:
    no_imgs: list, No. of samples per family
    list_fams: list, per family name
    '''
    inp_dir = r'../../autodl-tmp/malimg_paper_dataset_imgs'
    # change work dir
    os.chdir(inp_dir)  # 工作路径影响之后使用的相对路径

    list_fams = os.listdir(os.getcwd()) #vector of strings with family names
    # ['Adialer.C', 'Agent.FYI', 'Allaple.A', 'Allaple.L', 'Alueron.gen!J', 'Autorun.K', 'C2LOP.gen!g', 'C2LOP.P', 'Dialplatform.B', 'Dontovo.A', 'Fakerean', 'Instantaccess', 'Lolyda.AA1', 'Lolyda.AA2', 'Lolyda.AA3', 'Lolyda.AT', 'Malex.gen!J', 'Obfuscator.AD', 'Rbot!gen', 'Skintrim.N', 'Swizzor.gen!E', 'Swizzor.gen!I', 'VB.AT', 'Wintrim.BX', 'Yuner.A']

    no_imgs = [] # No. of samples per family
    for family in range(len(list_fams)):
        # family 取值为[0, 25)
        os.chdir(list_fams[family])
        no_per_family = len(glob.glob('*.png'))
        no_imgs.append(no_per_family)
        os.chdir('..')
    return no_imgs, list_fams

def getlabels(no_imgs, total):
    '''
    获取每个样本的标签
    :param no_imgs: list, No. of samples per familly
    :param total:  int, 9339 全部样本数
    :return:
    y: 包含全部样本标签的向量
    '''
    # y，存储每个样本标签的向量
    y = np.zeros(total) #label vector

    # temp1/temp2 都是中间变量
    temp1 = np.zeros(len(no_imgs)+1)
    temp1[1:len(temp1)] = no_imgs #transform list to ndarray
    temp2 = int(temp1[0]) #used to be as lower bound, initially 0

    # 为每个family内的样本生成标签
    for label in range(len(no_imgs)):
       temp3 = temp2 + int(temp1[label+1]) #No. of imgs assigned labels from 2 round
       #print("temp3", temp3)
       #print("label", label)
       for index in range(temp2, temp3):# assigned labels to a fam of malware
           # (temp2, temp3)指示每个family的样本范围
            y[index] = label
       temp2 = temp2 + int(temp1[label + 1])
    #print(y[100:200])
    return np.array(y)

def getX(list_fams, total):
    '''

    :param list_fams: list, per family name
    :param total: int, 9339 全部样本数
    :return:
    trans_mat_arr: 用clahe算法处理过的数据矩阵
    '''
    trans_mat_arr = list() #pixel ranges between 0 and 255, in total 256
    total_time = 0
    min_time = 10
    for i in range(len(list_fams)):
      os.chdir(list_fams[i])
      img_list = glob.glob('*.png')# Getting only 'png' files in a folder
      for j in range(len(img_list)):
         img = cv2.imread(img_list[j], 0)
       # create a CLAHE object (Arguments are optional).
       #   clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))

         tic = time.perf_counter()
         # cl1 = clahe.apply(img)
         cl1 = cv2.resize(img, (64,64), interpolation = cv2.INTER_AREA)
         cl1 = cv2.applyColorMap(cl1, cv2.COLORMAP_COOL)
         cl1 = cv2.cvtColor(cl1, cv2.COLOR_BGR2RGB)
         toc = time.perf_counter()

         fir_step_time = toc - tic
         total_time = total_time + fir_step_time
         if fir_step_time < min_time:
             min_time = fir_step_time
         trans_mat_arr.append(cl1)
         # print(f"the period of calling transition_matrix function in {fir_step_time:0.4f} seconds")
      os.chdir('..')

    # 全部样本处理完之后trans_mat_arr.__len__ = 全部样本数
    # trans_mat_arr[0].shape = trans_mat_arr[1].shape = ... = (64, 64)
    print(f"the average time per image {total_time / total:0.4f} seconds")
    print(f"the fewest time taken for an image {min_time:0.4f} seconds")
    return np.array(trans_mat_arr)

def strtifiedkfolddata(X, y, total, kfold):
    # kfold = 10, 将数据分为10份，一份用作验证，余下k-1分用作测试
    #p = np.arange(total)# an index array, 0:n_samples
    #random.seed(random.random())
    #random.shuffle(p)# the index array is now shuffled
    #X_shuffle, y_shuffle = X[p], y[p]# both the arrays are now shuffled
    skf = StratifiedKFold(kfold)
    #print("skf.get_n_splits", skf.get_n_splits(X, y))
    skfind = [None]*skf.get_n_splits(X, y)# indices
    cnt = 0
    for train_index in skf.split(X, y):
       skfind[cnt] = train_index
       cnt = cnt + 1
    #print("train_shuffle", skfind[0][0][100:200])
    #print("test_shuffle", skfind[0][1][100:200])
    #print("y_train_shuffle", y[skfind[0][0][100:200]])
    #print("y_shuffle", y[skfind[0][1][100:200]])
    return skfind

def Mal_Vgg16(no_imgs, image_size, in_channels):
    model = Sequential()

    model.add(Conv2D(64, (3,3), strides = (1,1), input_shape = (image_size, image_size, in_channels), padding = 'same', activation = 'relu'))
    model.add(Conv2D(64, (3,3), strides = (1,1), padding = 'same', activation = 'relu'))
    model.add(MaxPooling2D((2,2), strides = (2,2)))

    model.add(Conv2D(128,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))
    model.add(Conv2D(128,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))
    model.add(MaxPooling2D((2,2), strides = (2,2)))

    model.add(Conv2D(256,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))
    model.add(Conv2D(256,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))
    model.add(Conv2D(256,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))
    model.add(MaxPooling2D((2,2), strides = (2,2)))

    model.add(Conv2D(512,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))
    model.add(Conv2D(512,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))
    model.add(Conv2D(512,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))
    model.add(MaxPooling2D((2,2), strides = (2,2)))

    model.add(Conv2D(512,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))
    model.add(Conv2D(512,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))
    model.add(Conv2D(512,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))
    model.add(MaxPooling2D((2,2), strides = (2,2)))

    model.add(Flatten())
    model.add(Dense(1024, activation = 'relu'))
    model.add(Dense(512, activation = 'relu'))
    model.add(Dense(len(no_imgs)))
    # model.add(Activation('softmax'))
    return model

# def model_cnn(no_imgs):
#     model = Sequential()
#     model.add(Conv2D(64, (5, 5),
#                      padding='same',  # 137, 115(15755) 该卷积层输出尺寸等于输入的尺寸，会对原图像自动填充 而valid不会对图像进行填充和改动。
#                      input_shape=(64, 64, 1), kernel_regularizer=regularizers.l2(0.01), activation="relu"))  # 256,256,256
#     model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))  # 128,128,256
#     model.add(Conv2D(128, (5, 5), padding='same', kernel_regularizer=regularizers.l2(0.01),activation="relu"))  # shape(128,128, 128
#     model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))  # shape(64, 64, 128)
#     model.add(
#         Conv2D(256, (2, 2), padding='same', kernel_regularizer=regularizers.l2(0.01), activation="relu"))  # shape(batch_size, 64, 64, 32)
#     model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))  # shape(batch_size, 32, 32, 32)
#     model.add(Dropout(0.5))
#     model.add(Flatten())
#     model.add(Dense(256, activation = 'relu'))
#     model.add(Dense(128, activation = 'relu'))
#     model.add(Dense(len(no_imgs)))
#     model.add(Activation('softmax'))
#     return model

def train():
    no_imgs, list_fams = num_img_fams_list() #a list storing num of images for each family
    print(no_imgs)
    total = sum(no_imgs) # total number of all samples
    print(total)
    X = getX(list_fams, total)
    y = getlabels(no_imgs, total)

    p = np.arange(total)  # an index array, 0:n_samples
    random.seed(random.random())
    random.shuffle(p)  # the index array is now shuffled
    X, y = X[p], y[p]  # both the arrays are now shuffled
    #print("y.shape", y.shape)
    kfold = 10# no. of folds (better to have this at the start of the code)
    skfind = strtifiedkfolddata(X, y, total, kfold)
    cvscores = []
    conf_mat = np.zeros((len(no_imgs), len(no_imgs)))  # Initializing the Confusion Matrix
    for i in range(kfold):
        train_indices = skfind[i][0]
        #print("train_indices", train_indices[100:200])
        test_indices = skfind[i][1]
        #print(test_indices[100:200])
        X_train = X[train_indices]
        # X_train = X_train.reshape((-1, 64, 64, 1)).astype(float)
        X_train = X_train.reshape((-1, 64, 64, 3)).astype(float)
        #print("X_train.shape", X_train.shape)
        y_train = y[train_indices]
        #print(y_train[100:200])
        y_train = np_utils.to_categorical(y_train, num_classes=len(no_imgs))
        #print("y_train.shape", y_train.shape)
        # X_test = X[test_indices].reshape((-1, 64, 64, 1)).astype(float)
        X_test = X[test_indices].reshape((-1, 64, 64, 3)).astype(float)
        y_test = y[test_indices]
        print(y_test[100:200])
        y_test_onehot = np_utils.to_categorical(y_test, num_classes=len(no_imgs))
        model = Mal_Vgg16(no_imgs, 64, 3)
        opt = SGD(lr=0.01, momentum=0.9)
        # Compile model
        model.compile(optimizer=opt, loss=losses.logcosh,metrics=['accuracy'])
        wandb.config = {
            "learning_rate": 0.01,
            "epochs": 10,
            "batch_size": 1,
            "momentum": 0.9,
        }
        epochs = wandb.config['epochs']
        callbacks_list = [  # ←----通过fit()的callbacks参数将回调函数传入模型中，该参数接收一个回调函数列表，可以传入任意数量的回调函数
            keras.callbacks.EarlyStopping(  # ←----如果不再改善，则中断训练
                monitor="val_loss",  # ←----监控模型的验证精度
                patience=3,  # ←----如果精度在两轮内都不再改善，则中断训练
            ),
            keras.callbacks.ModelCheckpoint(  # ←----在每轮过后保存当前权重
                filepath="../../autodl-tmp/save_model/vgg16_keras_malimg.keras",  # ←----模型文件的保存路径
                monitor="val_loss",  # ←---- 这两个参数的含义是，只有当val_loss改善时，才会覆盖模型文件，这样就可以一直保存训练过程中的最佳模型
                save_best_only=True,
            ),
            WandbCallback()
        ]
        # Fit the model
        history = model.fit(X_train, y_train, epochs=epochs, batch_size=1, verbose=1, callbacks=[callbacks_list], validation_data=(X_test, y_test_onehot))

        # evaluate the model
        avg_acc = np.mean(history.history['val_accuracy'])
        print("avg_acc:", avg_acc)

        # Testing
        tic = time.time()
        y_predict = model.predict(X_test)  # output is labels and not indices
        toc = time.time()
        print("testing time = ", toc - tic)  # roughly 0.3 secs
        y_predict = np.argmax(y_predict,  axis=1)
        print(y_predict[0:100])
        print(y_test[0:100])
        # Compute confusion matrixnp.array([label.index(max(label)) for label in y_predict.tolist()])
        print('Confusion Matrix')
        print(confusion_matrix(y_test, y_predict))
        # print('Classification Report')
        # print(classification_report(y_test, y_predict, target_names=list_fams))
        #cm = confusion_matrix(y_test, y_predict)
        #conf_mat = conf_mat + cm
    #conf_mat_norm = conf_mat / no_imgs
    #conf_mat2 = np.around(conf_mat_norm, decimals=2)  # rounding to display in figure
if __name__ == "__main__":
    train()